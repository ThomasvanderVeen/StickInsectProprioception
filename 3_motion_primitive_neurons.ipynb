{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook 3: Movement Primitive Interneurons\n",
    "\n",
    "### General Overview\n",
    "\n",
    "The movement primitive layer contains 672 movement primitive (MP) interneurons (INs) that act as coincidence detectors, firing whenever two or three inputs overlap. Each input is a velocity or position spike train from a different joint (α, β, γ) within a leg. All possible combinations result in 112 unique MP INs per leg, totaling 672 across all legs. The aim of this layer is to signal leg-specific parameters, such as the swing phase, stance phase, or transitions between these phases.\n",
    "\n",
    "### Cell-by-Cell Description\n",
    "\n",
    "#### Importing Modules and Creating Folders\n",
    "\n",
    "This cell serves to import general functions, modules, and dictionaries from the 'general' module. Additionally, it imports the LIF class, which is integral to subsequent analyses. The LIF class is a simplified LIF neuron, see 'classes.py' for more information.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42090abe93b88d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from general import *\n",
    "from classes import LIF\n",
    "\n",
    "create_folder_if_not_exists('images')\n",
    "create_folder_if_not_exists('images/motion_primitive_neuron')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24c70ef37e122354"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defining Functions\n",
    "\n",
    "This cell defines several useful functions.\n",
    "\n",
    "*get_encoding()*\n",
    "\n",
    "Generates synapse connection permutations, synapse types, weights, and masks for given position and velocity weights.\n",
    "\n",
    "*prepare_spikes_primitive()*\n",
    "\n",
    "This function intertwines velocity and position spike trains, applies the permutations generated in get_encoding() and applies a positive mask.\n",
    "\n",
    "*get_stance_swing_bins()*\n",
    "\n",
    "This function extracts likelihood of spiking in each swing and stance bin from the spiking activity of a neuron. This can be extracted from annotated gait data and spike trains. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "204811a1a515adfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generates encoding permutations, synapse types, weights, and masks for given position and velocity weights.\n",
    "def get_encoding(w_pos=[0, 0, 0, 0, 0, 0, 0], w_vel=[0, 0, 0, 0, 0, 0, 0], n=6, n_simulations=1):\n",
    "    \n",
    "    # Define the possible synapse connections from 1st order interneurons, and assign them an integer\n",
    "    connections_str = ['none', 'Vel-', 'Vel+', 'Pos-', 'Pos+']\n",
    "    connections_int = [-np.inf, 0, 1, 2, 3]\n",
    "\n",
    "    # Generate all possible permutations of 3 synapse connections\n",
    "    connections_permutated_str = np.array(list(product(connections_str, repeat=3)))\n",
    "    connections_permutated_int = np.array(list(product(connections_int, repeat=3)))\n",
    "\n",
    "    synapse_type = []\n",
    "\n",
    "    # Determine synapse type for each permutation, e.g., synapse type 0 is E_0 or p-p. \n",
    "    for permutation in connections_permutated_str:\n",
    "        if 'none' in permutation:\n",
    "            # Check if 2 position synapse connections are present with 1 'none', E_1, p-p is synapse type 0\n",
    "            if (permutation == 'Pos+').sum() + (permutation == 'Pos-').sum() == 2:\n",
    "                synapse_type.append(0)\n",
    "            # Check if 2 velocity synapse connections are present with 1 'none', E_2, v-v is synapse type 1\n",
    "            elif (permutation == 'Vel+').sum() + (permutation == 'Vel-').sum() == 2:\n",
    "                synapse_type.append(1)\n",
    "            # Check if 1 position and 1 velocity synapse connections are present with 1 'none', E_3, p-v is synapse type 2\n",
    "            elif (permutation == 'Pos+').sum() + (permutation == 'Pos-').sum() == 1 and (permutation == 'Vel+').sum() + (permutation == 'Vel-').sum() == 1:\n",
    "                synapse_type.append(2)\n",
    "            else:\n",
    "            # These are the combinations with more than one 'none', to be discarded later\n",
    "                synapse_type.append(-1)\n",
    "        else:\n",
    "            # Check if 2 position and 1 velocity synapse connections are present, E_4, p-p-v is synapse type 3\n",
    "            if (permutation == 'Pos+').sum() + (permutation == 'Pos-').sum() == 2:\n",
    "                synapse_type.append(3)\n",
    "            # Check if 2 velocity and 1 position synapse connections are present, E_5, v-v-p is synapse type 4\n",
    "            elif (permutation == 'Vel+').sum() + (permutation == 'Vel-').sum() == 2:\n",
    "                synapse_type.append(4)\n",
    "            # Check if 3 position synapse connections are present, E_6, p-p-p is synapse type 5\n",
    "            elif (permutation == 'Pos+').sum() + (permutation == 'Pos-').sum() == 3:\n",
    "                synapse_type.append(5)\n",
    "            # Otherwise it has 3 velocity synapse connections, E_7, v-v-v is synapse type 6\n",
    "            else:\n",
    "                synapse_type.append(6)\n",
    "\n",
    "    # Filter out invalid synapse types (-1), with more than 1 'none'\n",
    "    zero_index = np.where(np.array(synapse_type) == -1)[0]\n",
    "    synapse_type = list(np.delete(synapse_type, zero_index))\n",
    "    connections_permutated_str = np.delete(connections_permutated_str, zero_index, axis=0)\n",
    "    connections_permutated_int = np.delete(connections_permutated_int, zero_index, axis=0)\n",
    "\n",
    "    # Initialize weights array, can be the same structure as \"connections_permutated_str\", because each synapse needs a weight\n",
    "    weights = np.zeros_like(connections_permutated_str, dtype=float)\n",
    "\n",
    "    # Assign weights based on encoding types, E_1 through E_7 and pos and vel connections carry different weights defined when calling this function\n",
    "    for i, j in np.ndindex(weights.shape):\n",
    "        if 'Pos' in connections_permutated_str[i, j]:\n",
    "            weights[i, j] = w_pos[synapse_type[i]]\n",
    "        elif 'Vel' in connections_permutated_str[i, j]:\n",
    "            weights[i, j] = w_vel[synapse_type[i]]\n",
    "\n",
    "    # Create masks for 'none' and non-'none' encodings. negative_mask -> none = 1, non-none = 0, positive mask -> none = 0, non-none = 1\n",
    "    negative_mask = np.zeros_like(connections_permutated_str, dtype=float)\n",
    "    negative_mask[connections_permutated_str == 'none'] = 1\n",
    "    negative_mask = np.tile(negative_mask, (6, 1))\n",
    "    negative_mask = negative_mask[:, :, np.newaxis].repeat(n_simulations, axis=2)\n",
    "    positive_mask = 1 - negative_mask\n",
    "\n",
    "    # Repeat weights and synapse types for 6 legs\n",
    "    weights = np.tile(weights, (6, 1))\n",
    "    weights = weights[:, :, np.newaxis].repeat(n_simulations, axis=2)\n",
    "    synapse_type = synapse_type * 6\n",
    "\n",
    "    # Add extra legs to connections_permutated_int (+12 per leg)\n",
    "    extra = np.array([0, 4, 8])\n",
    "    extra = np.tile(extra, (connections_permutated_int.shape[0], 1))\n",
    "    connections_permutated_int_legs = (connections_permutated_int + extra).clip(min=0)\n",
    "    extra_2 = np.linspace(0, 12 * (n - 1), num=n).repeat(3 * connections_permutated_int_legs.shape[0])\n",
    "    connections_permutated_int_legs = (np.tile(connections_permutated_int_legs.flatten(), n) + extra_2).astype(int)\n",
    "\n",
    "    # Increment connections_permutated_int such that none = 0 and vel- = 1 etc.\n",
    "    connections_permutated_int = connections_permutated_int + 1\n",
    "    connections_permutated_int[connections_permutated_int == -np.inf] = 0\n",
    "\n",
    "    return connections_permutated_str, connections_permutated_int.astype(int), connections_permutated_int_legs, synapse_type, weights, positive_mask, negative_mask\n",
    "\n",
    "# This function intertwines velocity and position spike trains, applies the permutations generated in get_encoding() and applies a positive mask\n",
    "def prepare_spikes_primitive(spike_velocity, spike_position, permutations, mask, n_simulations=1):    \n",
    "    # Initialize an empty tuple to hold combined velocity and position spikes\n",
    "    toepel = ()\n",
    "    \n",
    "    # Loop through the range to combine velocity and position spikes in pairs\n",
    "    # [vel-, vel+, pos-, pos+, vel-, vel+, etc.]\n",
    "    # [0, 1, 2, 3, 4, 5, 6, etc.] would be the permutation code\n",
    "    for i in range(18):\n",
    "        toepel += (spike_velocity[[0 + 2 * i, 1 + 2 * i]], spike_position[[0 + 2 * i, 1 + 2 * i]])\n",
    "\n",
    "    # Concatenate all the pairs to form a single array\n",
    "    pos_vel_spikes = np.concatenate(toepel)\n",
    "    \n",
    "    # Apply permutations and reshape to match the mask shape, then apply the mask\n",
    "    pos_vel_spikes = pos_vel_spikes[permutations].reshape(mask.shape) * mask\n",
    "\n",
    "    return pos_vel_spikes\n",
    "\n",
    "\n",
    "def get_stance_swing_bins(gait, spike_train, n_bins):\n",
    "    \n",
    "    # Identify the indices (timestep) where the gait phase changes, either swing to stance or stance to swing\n",
    "    change_index = np.where(gait[:-1] != gait[1:])[0]\n",
    "    \n",
    "    # Calculate the number of complete swing_stance phases\n",
    "    n_phases = (change_index.size // 2) - 1\n",
    "\n",
    "    # Initialize arrays to hold spike rates and likelihoods of spiking for each bin and phase\n",
    "    swing_bin_rate = np.zeros((n_phases, n_bins))\n",
    "    stance_bin_rate = np.zeros((n_phases, n_bins))\n",
    "    swing_bin_likelihood = np.zeros((n_phases, n_bins))\n",
    "    stance_bin_likelihood = np.zeros((n_phases, n_bins))\n",
    "\n",
    "    # Loop through each phase to calculate spike rates and likelihoods\n",
    "    for i in range(n_phases):\n",
    "        # Calculate the index that this phases' swing starts, ends and stance ends. end_swing = start_stance\n",
    "        start_idx_swing = change_index[2 * i + (1 if gait[0] == 0 else 0)]\n",
    "        end_idx_swing = change_index[1 + 2 * i + (1 if gait[0] == 0 else 0)]\n",
    "        end_idx_stance = change_index[2 + 2 * i + (1 if gait[0] == 0 else 0)]\n",
    "\n",
    "        # extract the swing and stance phase spike trains, and split them in n_bins\n",
    "        spikes_swing = np.array_split(spike_train[start_idx_swing:end_idx_swing], n_bins)\n",
    "        spikes_stance = np.array_split(spike_train[end_idx_swing:end_idx_stance], n_bins)\n",
    "\n",
    "        # Calculate the total spike count for each bin\n",
    "        for j in range(n_bins):\n",
    "            swing_bin_rate[i, j] = np.sum(spikes_swing[j])\n",
    "            stance_bin_rate[i, j] = np.sum(spikes_stance[j])\n",
    "\n",
    "        # Calculate the likelihood of spiking in each bin\n",
    "        stance_bin_likelihood[i, stance_bin_rate[i, :] > 0.5] = 1\n",
    "        swing_bin_likelihood[i, swing_bin_rate[i, :] > 0.5] = 1\n",
    "\n",
    "    # Compute the average spike rates and likelihoods across all phases\n",
    "    swing_bin_rate = np.mean(swing_bin_rate, axis=0)\n",
    "    stance_bin_rate = np.mean(stance_bin_rate, axis=0)\n",
    "    swing_bin_likelihood = np.mean(swing_bin_likelihood, axis=0)\n",
    "    stance_bin_likelihood = np.mean(stance_bin_likelihood, axis=0)\n",
    "\n",
    "    return swing_bin_rate, stance_bin_rate, swing_bin_likelihood, stance_bin_likelihood"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b9053ba7dfc9f73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Movement Primitive Ground Truth\n",
    "\n",
    "Based on the real joint angles, it is possible to determine when a certain joint is moving forward (vel+), moving backward (vel-), is in the positive domain with respect to rest (pos+), or is in the negative domain with respect to rest (pos-). Reference spike trains for these first-order interneurons can be created. By applying the same preprocessing as used for the movement primitive neurons, a ground truth reference for the movement primitive neurons can be established. Performance can then be assessed against this ground truth by constructing a confusion matrix. First, the joint angles are loaded. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "173bf32efcb86b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load joint angles, position spike data and velocity spike data from files\n",
    "with open('temp_data/joint_angles.npy', 'rb') as file:\n",
    "    joint_angles = np.load(file)\n",
    "    \n",
    "with open('temp_data/spike_position', 'rb') as file:\n",
    "    spike_position = np.load(file) \n",
    "    \n",
    "with open('temp_data/spike_velocity', 'rb') as file:\n",
    "    spike_velocity = np.load(file) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2633992e4dfd4448"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The permutations are extracted from *get_encoding()*, and arrays are initialized."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ce80ab13e52557a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "N_BINS = 100\n",
    "\n",
    "# Retrieve permutation parameters, synapse types, weights and masks. \n",
    "perm, perm2, permutations_final, synapse_type, weights_primitive, mask_positive, mask_negative = get_encoding([0]*7, [0]*7, n_simulations=parameters['N_SIMULATIONS'])\n",
    "\n",
    "# Initialize ground truth arrays\n",
    "ground_truth = np.empty((constants['N_STEPS'], len(synapse_type), parameters['N_SIMULATIONS']))\n",
    "ground_truth_bins = np.zeros((N_BINS, len(synapse_type), parameters['N_SIMULATIONS']))\n",
    "ground_vel, ground_pos = np.zeros((constants['N_STEPS'], 36, parameters['N_SIMULATIONS'])), np.zeros((constants['N_STEPS'], 36, parameters['N_SIMULATIONS']))\n",
    "\n",
    "# Initialize confusion matrix components\n",
    "true_positive, false_positive, true_negative, false_negative = [\n",
    "    np.zeros((len(synapse_type), parameters['N_SIMULATIONS'])) for _ in range(4)\n",
    "]\n",
    "\n",
    "# Initialize group-level confusion matrix components\n",
    "true_positive_groups, false_positive_groups, true_negative_groups, false_negative_groups = [\n",
    "    np.zeros(7) for _ in range(4)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a01fbad7ee08f54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loop through each joint angle to calculate velocity and position reference spike trains\n",
    "for i in tqdm(range(constants['N_ANGLES'])):\n",
    "    \n",
    "    # Calculate the resting angle value of the joint angle range for current joint\n",
    "    resting_angle = np.max(joint_angles[:, i, :parameters['N_SIMULATIONS']], axis=(0, 1)) / 2 + \\\n",
    "                    np.min(joint_angles[:, i, :parameters['N_SIMULATIONS']], axis=(0, 1)) / 2\n",
    "    \n",
    "    # Calculate the velocity by differentiating joint angles and dividing by time step\n",
    "    diff = np.diff(joint_angles[:, i, :parameters['N_SIMULATIONS']], axis=0) / constants['dt']\n",
    "    \n",
    "    # Identify indices (timestep and simulation) where joint velocity is negative (moving backward) and positive (moving forward)\n",
    "    vel_dt_min, vel_sim_min = np.where(diff < 0)[0], np.where(diff < 0)[1]\n",
    "    vel_dt_plus, vel_sim_plus = np.where(diff > 0)[0], np.where(diff > 0)[1]\n",
    "    \n",
    "    # Identify indices where joint angle is in the negative domain and positive domain relative to the resting angle\n",
    "    pos_dt_min, pos_sim_min = np.where(joint_angles[:, i, :parameters['N_SIMULATIONS']] < resting_angle)[0], np.where(joint_angles[:, i, :parameters['N_SIMULATIONS']] < resting_angle)[1]\n",
    "    pos_dt_plus, pos_sim_plus = np.where(joint_angles[:, i, :parameters['N_SIMULATIONS']] > resting_angle)[0], np.where(joint_angles[:, i, :parameters['N_SIMULATIONS']] > resting_angle)[1]\n",
    "    \n",
    "    # Assign spikes to the ground velocity and position arrays based on identified indices\n",
    "    ground_vel[vel_dt_min, 0 + 2 * i, vel_sim_min] = 1\n",
    "    ground_vel[vel_dt_plus, 1 + 2 * i, vel_sim_plus] = 1\n",
    "    ground_pos[pos_dt_min, 0 + 2 * i, pos_sim_min] = 1\n",
    "    ground_pos[pos_dt_plus, 1 + 2 * i, pos_sim_plus] = 1\n",
    "\n",
    "# Loop through each step to prepare and process spikes just like the movement primitive layer, creating ground truth reference\n",
    "for j in tqdm(range(constants['N_STEPS'])):\n",
    "    # Prepare spikes for current step using velocity and position reference spikes, add a negative mask such that a none connection adds is a spike\n",
    "    ground_truth_j = prepare_spikes_primitive(ground_vel[j, :, :parameters['N_SIMULATIONS']], \n",
    "                                              ground_pos[j, :, :parameters['N_SIMULATIONS']], \n",
    "                                              permutations_final, \n",
    "                                              mask_positive, \n",
    "                                              n_simulations=parameters['N_SIMULATIONS']) + mask_negative\n",
    "    # Sum across the first axis (all three inputs)\n",
    "    ground_truth_j = np.sum(ground_truth_j, axis=1)\n",
    "    \n",
    "    # If all three inputs were a spike, i.e. 1. The ground truth movement primitive output should be 1, otherwise 0.\n",
    "    ground_truth[j, ground_truth_j > 2.9] = 1\n",
    "    ground_truth[j, ground_truth_j < 2.9] = 0\n",
    "\n",
    "# Convert ground truth data to bins for each simulation, the bins are used to compare with the movement primitive spikes\n",
    "for k in range(parameters['N_SIMULATIONS']):\n",
    "    ground_truth_bins[:, :, k] = convert_to_bins(ground_truth[:, :, k], N_BINS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66d05e040062f7a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optimizing the Movement Primitive Layer\n",
    "\n",
    "With the ground truth determined, the movement primitive layer can be optimized. The time constant $\\tau$ and the weights $\\omega_\\text{vel}$ and $\\omega_\\text{pos}$ are varied in a grid search method. For each iteration, the matthews correlation coefficient (MCC) is calculated.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b75af91cf813eb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if parameters['run_optimization']:\n",
    "    # Define number of weights and tau values for the grid search optimization\n",
    "    N_WEIGHTS = 9\n",
    "    N_TAU = 7\n",
    "    \n",
    "    # Generate lists of tau and weight values for position and velocity\n",
    "    tau_list = np.linspace(0e-3, 0.6e-3, num=N_TAU)\n",
    "    w_pos_list = np.linspace(2e-3, 18e-3, num=N_WEIGHTS)\n",
    "    w_vel_list = np.linspace(2e-3, 18e-3, num=N_WEIGHTS)\n",
    "    \n",
    "    # Initialize arrays for storing movement primitive spikes and MCC values\n",
    "    spike_primitive = np.empty((constants['N_STEPS'], len(synapse_type), parameters['N_SIMULATIONS']), dtype=np.uint8)\n",
    "    mcc_list = np.zeros((7, N_TAU, N_WEIGHTS, N_WEIGHTS))\n",
    "    \n",
    "    # Iterate over all combinations of tau and weight values\n",
    "    for p, l, m in tqdm(np.ndindex(N_TAU, N_WEIGHTS, N_WEIGHTS), desc=f'Total iterations: {N_TAU * N_WEIGHTS * N_WEIGHTS}'):\n",
    "        \n",
    "        # Set weights for position and velocity\n",
    "        w_pos = [w_pos_list[l], 0, w_pos_list[l], w_pos_list[l], w_pos_list[l], w_pos_list[l], 0]\n",
    "        w_vel = [0, w_vel_list[m], w_vel_list[m], w_vel_list[m], w_vel_list[m], 0, w_vel_list[m]]\n",
    "        \n",
    "        # Get encoding parameters with current weights\n",
    "        _, _, permutations_final, synapse_type, weights_primitive, mask_positive, mask_negative = get_encoding(w_pos, w_vel, n_simulations=parameters['N_SIMULATIONS'])\n",
    "        \n",
    "        # Define parameters for the LIF neuron model, setting tau and the weights\n",
    "        primitive_parameters = {\n",
    "            'tau': tau_list[p],                     # time constant tau\n",
    "            'V_T': -50e-3, \n",
    "            'V_R': -70e-3, \n",
    "            'n': len(synapse_type),                 # The number of movement primitive neurons\n",
    "            'w': weights_primitive,                 # The weights (3, 672), 672 is number of movement primitive neurons\n",
    "            'N_input': 3,                           # 3 synapse connections per movement primitive neuron\n",
    "            'dt': constants['dt'], \n",
    "            'n_sims': parameters['N_SIMULATIONS'],  # This simulation can run parallel for each trial\n",
    "            'multiple_synapses': True               # Multiple input synapses (3)\n",
    "        }\n",
    "        \n",
    "        # Initialize the LIF neuron model\n",
    "        primitive_neuron = LIF(primitive_parameters)\n",
    "        primitive_neuron.initialize_state()\n",
    "        \n",
    "        # Forward pass for each time step\n",
    "        for i in range(constants['N_STEPS']):\n",
    "            # Change the spikes structure\n",
    "            pos_vel_spikes = prepare_spikes_primitive(\n",
    "                spike_velocity[i, :, :parameters['N_SIMULATIONS']], \n",
    "                spike_position[i, :, :parameters['N_SIMULATIONS']], \n",
    "                permutations_final, \n",
    "                mask_positive, \n",
    "                parameters['N_SIMULATIONS']\n",
    "            )\n",
    "            # Run the primitive neurons one step forward\n",
    "            _, spike_primitive[i, :, :] = primitive_neuron.forward(pos_vel_spikes)\n",
    "        \n",
    "        # Calculate confusion matrix components for each simulation\n",
    "        for k in range(parameters['N_SIMULATIONS']):\n",
    "            # Bin the movement primitive spikes, a bin is set to 1 if one element is 1 and 0 if all elements are 0. \n",
    "            spike_primitive_bins = convert_to_bins(spike_primitive[:, :, k], N_BINS)\n",
    "            # Loop over all 672 movement primitive neurons, and produce a confusion matrix for each simulation and neuron\n",
    "            for i in range(primitive_parameters['n']):\n",
    "                tp, fp, tn, fn = get_confusion_matrix(spike_primitive_bins[:, i], ground_truth_bins[:, i, k])\n",
    "                true_positive[i, k], false_positive[i, k], true_negative[i, k], false_negative[i, k] = tp, fp, tn, fn\n",
    "        \n",
    "        # Calculate MCC for each synapse type group\n",
    "        for i in range(7):  \n",
    "            indices = np.where(np.array(synapse_type) == i)\n",
    "            true_positive_groups[i] = np.sum(true_positive[indices, :])\n",
    "            true_negative_groups[i] = np.sum(true_negative[indices, :])\n",
    "            false_positive_groups[i] = np.sum(false_positive[indices, :])\n",
    "            false_negative_groups[i] = np.sum(false_negative[indices, :])\n",
    "            \n",
    "            mcc = matthews_correlation(true_positive_groups[i], true_negative_groups[i], false_positive_groups[i], false_negative_groups[i])\n",
    "            mcc_list[i, p, l, m] = mcc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3770dfc0881a2c64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the mcc_list we can extract the optimal weights per time constant value, used later for plotting purposes. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e0c5720832b190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if parameters['run_optimization']:\n",
    "    # Initialize arrays to store optimal weights and accuracy\n",
    "    w_1_opt, w_2_opt, accuracy_opt = np.zeros([N_TAU, 7]), np.zeros([N_TAU, 7]), np.zeros([N_TAU, 7])\n",
    "\n",
    "    # Iterate over each time constant value\n",
    "    for i in range(N_TAU):\n",
    "        # Iterate over each synapse type group (E_1 through E_7)\n",
    "        for j in range(7):\n",
    "            # Find the indices of the maximum MCC value for the current time constant and synapse type group\n",
    "            max_indices = np.unravel_index(np.argmax(mcc_list[j, i, :, :]), mcc_list[j, i, :, :].shape)\n",
    "    \n",
    "            # Extract optimal weight values for position and velocity from the indices\n",
    "            w_1_opt[i, j] = w_pos_list[max_indices[0]]\n",
    "            w_2_opt[i, j] = w_vel_list[max_indices[1]]\n",
    "    \n",
    "            # Store the maximum MCC value as the optimal accuracy\n",
    "            accuracy_opt[i, j] = mcc_list[j, i, max_indices[0], max_indices[1]]\n",
    "\n",
    "    w_1_opt[:, [1, 6]] = 0 \n",
    "    w_2_opt[:, [0, 5]] = 0 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad1b542e09ba7446"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This figure shows the MCC scores for each synapse type group and the mean for each time constant value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b39c09177b962fe6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if parameters['run_optimization']:\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot accuracy for each synapse type group\n",
    "    for i in range(7):\n",
    "        ax.plot(tau_list * 1000, accuracy_opt[:, i], color=custom_colors[i], linestyle=custom_linestyles[i], marker=custom_markers[i])\n",
    "    ax.plot(tau_list * 1000, np.mean(accuracy_opt, axis=1), color='black')\n",
    "    \n",
    "    # Set axis parameters\n",
    "    ax.minorticks_on()\n",
    "    ax.set_xlabel('τ (ms)')\n",
    "    ax.set_ylabel(\"Matthews correlation\")\n",
    "    ax.set_xticks(1000 * tau_list)\n",
    "    \n",
    "    # Add figure legend and pad\n",
    "    fig.legend(['p-p', 'v-v', 'p-v', 'p-p-v', 'v-v-p', 'p-p-p', 'v-v-v', 'mean'], loc='upper center',\n",
    "               bbox_to_anchor=(1.09, 0.92), frameon=False)\n",
    "    fig.tight_layout(pad=parameters['pad'])\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig('images/motion_primitive_neuron/P2_fig2a.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da18630aa001fd5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This barplot shows the optimal $\\omega_\\text{pos}$ and $\\omega_\\text{vel}$ for each time constant. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2d3850a90bded25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if parameters['run_optimization']:\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, ax = plt.subplots(2)\n",
    "\n",
    "    # Calculate width for bars based on tau_list spacing\n",
    "    width = 100 * (tau_list[1] - tau_list[0])\n",
    "    \n",
    "    # Iterate over each tau value and each synapse type group\n",
    "    for i in range(tau_list.size):\n",
    "        for j in range(7):\n",
    "            # Plot bar for w_1_opt (omega_pos) in the first subplot\n",
    "            ax[0].bar(tau_list[i] * 1000 + (-3 * width + width * j), w_1_opt[i, j] * 1000, width, color=custom_colors[j])\n",
    "            # Plot bar for w_2_opt (omega_vel) in the second subplot\n",
    "            ax[1].bar(tau_list[i] * 1000 + (-3 * width + width * j), w_2_opt[i, j] * 1000, width, color=custom_colors[j])\n",
    "    \n",
    "    # Enable gridlines on both subplots along the y-axis\n",
    "    ax[0].grid(True, axis='y')\n",
    "    ax[1].grid(True, axis='y')\n",
    "    \n",
    "    # Configure ticks and labels\n",
    "    ax[0].set_xticks([])  # No x ticks for the first subplot\n",
    "    ax[0].set_yticks(1000 * w_pos_list[::2])  # Set y-axis ticks for omega_pos (w_pos)\n",
    "    ax[1].set_yticks(1000 * w_vel_list[::2])  # Set y-axis ticks for omega_vel (w_vel)\n",
    "    ax[1].set_xticks(1000 * tau_list)  # Set x-axis ticks for tau values in milliseconds\n",
    "    \n",
    "    ax[0].set_ylabel(r'$\\omega_{pos}$ (mV)')  # Set y-axis label for omega_pos (w_pos)\n",
    "    ax[1].set_ylabel(r'$\\omega_{vel}$ (mV)')  # Set y-axis label for omega_vel (w_vel)\n",
    "    ax[1].set_xlabel('τ (ms)')  # Set x-axis label for tau in milliseconds\n",
    "    \n",
    "    # Add legend specifying synapse type groups\n",
    "    fig.legend(['p-p', 'v-v', 'p-v', 'p-p-v', 'v-v-p', 'p-p-p', 'v-v-v'], loc='upper center', bbox_to_anchor=(1.09, 0.87), frameon=False)\n",
    "    \n",
    "    # Adjust figure layout with specified padding\n",
    "    fig.tight_layout(pad=parameters['pad'])\n",
    "    \n",
    "    # Save the figure as a PNG file\n",
    "    fig.savefig('images/motion_primitive_neuron/P2_fig2b.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea5a0eb9b1bf8d44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cell determines the optimal tau value, and their corresponding weights. These weights are then saved for later use."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c038e2438750"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if parameters['run_optimization']:\n",
    "    # Calculate maximum MCC values across all synapse types\n",
    "    mcc_list_max = np.max(mcc_list, axis=(1, 2, 3))\n",
    "    \n",
    "    # Calculate weighted average of maximum MCC values by synapse type\n",
    "    average_mcc_max = np.average(mcc_list_max, weights=np.bincount(synapse_type), axis=0)\n",
    "    \n",
    "    # Find index of optimal tau based on average accuracy\n",
    "    tau_opt_index = np.argmax(np.mean(accuracy_opt, axis=1))\n",
    "    \n",
    "    # Create a table with MCC values, omega_pos, and omega_vel according to the optimal tau\n",
    "    table = {'MCC': np.around(mcc_list_max, 3),\n",
    "             '\\u03C9_pos':  w_1_opt[tau_opt_index, :],\n",
    "             '\\u03C9_vel':  w_2_opt[tau_opt_index, :]}\n",
    "    \n",
    "    # Make and safe dataframe\n",
    "    df = pd.DataFrame(data=table, index=['p-p', 'v-v', 'p-v', 'p-p-v', 'v-v-p', 'p-p-p', 'v-v-v'])\n",
    "    df.to_csv('results/primitive_accuracy_table.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c97dc6359f9ffda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cell extracts the optimal weight values to be used in further calculations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b84a8fd778cbcc9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the accuracy table from CSV file into a DataFrame\n",
    "df = pd.read_csv('results/primitive_accuracy_table.csv')\n",
    "\n",
    "# Extract optimal values of w_pos and w_vel from DataFrame\n",
    "W_POS = list(df['\\u03C9_pos'].values)\n",
    "W_VEL = list(df['\\u03C9_vel'].values)\n",
    "\n",
    "# Print DataFrame columns for omega_pos and omega_vel\n",
    "print(df[['\\u03C9_pos', '\\u03C9_vel']])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "333b0ef4e109a037"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Running the Movement Primitive Neurons\n",
    "\n",
    "Using the optimal parameter set described before, we can run the movement primitive neurons using the velocity and position spike trains."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1be589bb833d85ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_primitive(spike_velocity, spike_position, n_simulations, n_steps):\n",
    "    # Obtain encoding parameters for movement primitives\n",
    "    _, _, permutations_final, synapse_type, weights_primitive, mask_positive, mask_negative = get_encoding(W_POS, W_VEL, n_simulations=n_simulations)\n",
    "    \n",
    "    # Define parameters for the primitive neuron\n",
    "    primitive_parameters = {\n",
    "        'tau': 0.2e-3,  \n",
    "        'V_T': -50e-3,  \n",
    "        'V_R': -70e-3,  \n",
    "        'n': len(synapse_type),  \n",
    "        'w': weights_primitive,  \n",
    "        'N_input': 3,  \n",
    "        'dt': constants['dt'],  \n",
    "        'n_sims': n_simulations,  \n",
    "        'multiple_synapses': True  \n",
    "    }\n",
    "    \n",
    "    # Initialize LIF neuron model\n",
    "    primitive_neuron = LIF(primitive_parameters)\n",
    "    primitive_neuron.initialize_state()\n",
    "    \n",
    "    # Array to store primitive neuron spike outputs\n",
    "    spike_primitive = np.empty((n_steps, primitive_parameters['n'], n_simulations), dtype=np.uint8)\n",
    "    \n",
    "    # Iterate over time steps and simulate primitive neuron activity\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        # Prepare spike trains for primitive neuron inputs\n",
    "        pos_vel_spikes = prepare_spikes_primitive(spike_velocity[i, :, :n_simulations], spike_position[i, :, :n_simulations], permutations_final, mask_positive, n_simulations)\n",
    "        \n",
    "        # Forward propagate inputs through the primitive neuron model\n",
    "        _, spike_primitive[i, :, :] = primitive_neuron.forward(pos_vel_spikes)\n",
    "    \n",
    "    return spike_primitive"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3620cd36b6a30c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load position and velocity spike trains from files\n",
    "with open('temp_data/spike_position_step', 'rb') as file:\n",
    "    spike_position_step = np.load(file) \n",
    "    \n",
    "with open('temp_data/spike_velocity_step', 'rb') as file:\n",
    "    spike_velocity_step = np.load(file) \n",
    "    \n",
    "# Run movement primitive neuron simulation for regular and step data\n",
    "spike_primitive = run_primitive(spike_velocity, spike_position, np.min((parameters['N_SIMULATIONS'], 78)), constants['N_STEPS'])\n",
    "spike_primitive_step = run_primitive(spike_velocity_step, spike_position_step, np.min((parameters['N_SIMULATIONS'], 21)), constants['N_STEPS_STEP'])\n",
    "\n",
    "# Save the movement primitive spike data if required\n",
    "if parameters['save_data']:\n",
    "    with open('temp_data/spike_primitive', 'wb') as file:\n",
    "            np.save(file, spike_primitive)\n",
    "    \n",
    "    with open('temp_data/spike_primitive_step', 'wb') as file:\n",
    "            np.save(file, spike_primitive_step)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80043818fa031549"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Swing and Stance Analysis ####\n",
    "\n",
    "Some movement primitive neurons demonstrate a distinct tendency to fire either during the swing phase, stance phase, or during transitions between these phases. The goal is to analyze this behavior by determining the likelihood of each movement primitive neuron to fire during predefined swing or stance bins."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5201f9047bf3e93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load gait data from file, 1 is swing and 0 is stance over time, for 6 legs and 72 trials\n",
    "with open('temp_data/gait.npy', 'rb') as file:\n",
    "    gait = np.load(file)\n",
    "\n",
    "# Constants and parameters\n",
    "N_PRIMITIVE_NEURONS = 672\n",
    "N_PN_PER_LEG = N_PRIMITIVE_NEURONS // 6\n",
    "N_BINS = 16\n",
    "\n",
    "# Arrays to store swing and stance bin likelihoods\n",
    "swing_bin_likelihood = np.zeros((N_BINS, N_PRIMITIVE_NEURONS, parameters['N_SIMULATIONS']))\n",
    "stance_bin_likelihood = np.zeros((N_BINS, N_PRIMITIVE_NEURONS, parameters['N_SIMULATIONS']))\n",
    "\n",
    "# Compute swing and stance bin likelihoods for each neuron and simulation\n",
    "for l, k in np.ndindex(N_PRIMITIVE_NEURONS, parameters['N_SIMULATIONS']):\n",
    "    _, _, swing_bin_likelihood[:, l, k], stance_bin_likelihood[:, l, k] = get_stance_swing_bins(gait[:, l // N_PN_PER_LEG, k], spike_primitive[:, l, k], n_bins=N_BINS)\n",
    "    \n",
    "# Average across simulations to get overall likelihoods\n",
    "swing_bin_likelihood = np.mean(swing_bin_likelihood, axis=2)\n",
    "stance_bin_likelihood = np.mean(stance_bin_likelihood, axis=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56b9b7eeb5961504"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To evaluate the performance of each Movement Primitive Interneuron (MP IN) as a swing, stance, swing→stance, or stance→swing encoder, we compare the `swing_bin_likelihood` and `stance_bin_likelihood` to target vectors.\n",
    "\n",
    "- The swing target vector is defined as: `[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]`\n",
    "- The swing→stance target vector is defined as: `[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]`\n",
    "\n",
    "By concatenating `swing_bin_likelihood` and `stance_bin_likelihood`, we can compute a score. A score of 1 for the swing target vector indicates perfect swing encoding, while a score of 0 indicates perfect stance encoding. The score for the swing→stance target vector is calculated analogously. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "977537d363d43b58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define target vectors\n",
    "swing_target = np.concatenate((np.ones(N_BINS), np.zeros(N_BINS)))\n",
    "swing_stance_target = np.concatenate((np.zeros(N_BINS//2), np.ones(N_BINS), np.zeros(N_BINS//2)))\n",
    "\n",
    "# Combine swing and stance bin likelihoods\n",
    "combined_bin_likelihood = np.vstack((swing_bin_likelihood, stance_bin_likelihood))\n",
    "\n",
    "# Calculate scores\n",
    "scores = [1 - np.around(np.mean(abs(combined_bin_likelihood - axis[:, np.newaxis].repeat(672, axis=1)), axis=0), 5) \n",
    "          for axis in [swing_target, swing_stance_target]]\n",
    "\n",
    "# Determine maximum and minimum values and their indices\n",
    "max_vals = [np.max(score) for score in scores]\n",
    "min_vals = [np.min(score) for score in scores]\n",
    "\n",
    "max_i = [np.where(score == max_val)[0][0] for score, max_val in zip(scores, max_vals)]\n",
    "min_i = [np.where(score == min_val)[0][0] for score, min_val in zip(scores, min_vals)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a68363ff3cff550"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cell plots the highest performing MP IN, illustrating presynaptic (input) spikes, postsynaptic (output) spikes, and their correlation with the gait pattern, particularly during the swing phase. The first three panels depict the input spike trains, which are related to the joint angles. The fourth panel visualizes the movement primitive spike train, indicating firing whenever the inputs overlap. The fifth panel displays the gait pattern, highlighting that the MP IN spikes coincide with the leg being in the swing phase."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "399c590108ec5773"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62a996a176981f3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trial = 0\n",
    "neuron_i = max_i[0]  # Index of the neuron with maximum swing score\n",
    "max_leg = neuron_i // 112  # Determine the leg index of the neuron\n",
    "max_leg_i = neuron_i % 112  # Index within the leg (ith movement primitive neuron)\n",
    "\n",
    "# Plotting variables\n",
    "joints = ['α', 'β', 'γ']\n",
    "LEGS = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "\n",
    "# Define a time array\n",
    "time = np.linspace(0, constants['T_TOTAL'], num=constants['N_STEPS'])\n",
    "\n",
    "# Create subplots with shared x-axis\n",
    "fig, [ax1, ax2, ax3, ax4, ax5] = plt.subplots(5, figsize=(5.7*0.95, 2.5), gridspec_kw={'height_ratios': [1, 1, 1, 1, 1]}, sharex='all')\n",
    "\n",
    "axs = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "# Extract spike data and handle zeros as NaN for plotting\n",
    "spike_primitive_plot = spike_primitive[:, neuron_i, trial].astype(float)\n",
    "spike_primitive_plot[spike_primitive_plot == 0] = np.nan\n",
    "\n",
    "spike_position_leg_i = spike_position[:, 6*max_leg:6*(max_leg+1), trial]\n",
    "spike_velocity_leg_i = spike_velocity[:, 6*max_leg:6*(max_leg+1), trial]\n",
    "\n",
    "# Plot joint angles and spikes for each joint\n",
    "for i in range(3):\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_ylabel(f'{joints[i]}\\n{perm[max_leg_i][i]}')\n",
    "\n",
    "    spike_vel_pos = np.hstack((spike_velocity_leg_i[:, 2*i:2*(i+1)], spike_position_leg_i[:, 2*i:2*(i+1)])).astype(float)\n",
    "    spike_vel_pos[spike_vel_pos == 0] = np.nan\n",
    "    \n",
    "    # Plot normalized joint angles and spikes\n",
    "    axs[i].scatter(time, zscore.zscore(joint_angles[:, 3*max_leg + i, trial]) * spike_vel_pos[:, perm2[max_leg_i][i]-1], s=1, color=custom_colors[0], marker='^', zorder=2)\n",
    "    axs[i].plot(time, zscore.zscore(joint_angles[:, 3*max_leg + i, trial]), color='black', linewidth=1, zorder=1)\n",
    "\n",
    "# Plot spike activity of the movement primitive neuron\n",
    "ax4.scatter(time, spike_primitive_plot, s=1, color=custom_colors[1], marker='^')\n",
    "\n",
    "# Plot gait pattern\n",
    "ax5.plot(time, gait[:, max_leg, trial], color=custom_colors[2])\n",
    "\n",
    "ax4.set_yticks([])\n",
    "ax4.set_ylabel('MP IN')\n",
    "\n",
    "# Customize figure title and axis labels\n",
    "fig.suptitle(f'Leg: {LEGS[max_leg]}, swing score: {scores[0][neuron_i]:.3f}, trial: {trial}')\n",
    "ax5.set_yticks([0, 1])\n",
    "labels = ['Swing', 'Stance']\n",
    "ax5.set_yticklabels(labels)\n",
    "ax5.set_xlabel('Time (s)')\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(f'images/motion_primitive_neuron/P2_fig3.png', bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca893f60dcaeb2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cell plots the highest performing MP IN response for each target phase: 'swing', 'Swing→stance', 'stance', 'Stance→swing'. The likelihood of spiking for each bin is plotted."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e73825b4dc059f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define naming conventions, phases and other plotting parameters\n",
    "naming = ['P2_fig4a', 'P2_fig4b', 'P2_fig4c', 'P2_fig4d']\n",
    "phase = ['swing', 'Swing→stance', 'stance', 'Stance→swing']\n",
    "LEGS = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "x = [1, 0, 0.5, 0.5]\n",
    "\n",
    "# Indices of the highest performing neurons for each phase (transition)\n",
    "val_i = [max_i[0], max_i[1], min_i[0], min_i[1]]\n",
    "\n",
    "# Iterate over each phase (transition) to create respective plots\n",
    "for i in range(4):\n",
    "    # Create a new figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(2.6, 2.6/1.618))\n",
    "    \n",
    "    # Plot the swing and stance likelihoods for the current phase\n",
    "    if phase[i] in ['swing', 'stance']:\n",
    "        ax.scatter(np.linspace(0, .725, num=N_BINS), swing_bin_likelihood[:, val_i[i]] * 100, color=custom_colors[0], marker='^')\n",
    "        ax.scatter(np.linspace(.775, 1.5, num=N_BINS), stance_bin_likelihood[:, val_i[i]] * 100, color=custom_colors[1], marker='^')\n",
    "        ax.set_title(f'Swing score: {scores[0][val_i[i]]:.3f}\\n{perm[val_i[i] % 112][0]}, {perm[val_i[i] % 112][1]}, {perm[val_i[i] % 112][2]}, leg: {LEGS[val_i[i] // 112]}')\n",
    "    else:\n",
    "        ax.scatter(np.linspace(0, .725, num=N_BINS), swing_bin_likelihood[:, val_i[i]] * 100, color=custom_colors[0], marker='^')\n",
    "        ax.scatter(np.linspace(.775, 1.5, num=N_BINS), stance_bin_likelihood[:, val_i[i]] * 100, color=custom_colors[1], marker='^')\n",
    "        ax.set_title(f'Swing→stance score: {scores[1][val_i[i]]:.3f}\\n{perm[val_i[i] % 112][0]}, {perm[val_i[i] % 112][1]}, {perm[val_i[i] % 112][2]}, leg: {LEGS[val_i[i] // 112]}')\n",
    "\n",
    "    # Set labels and ticks for axes\n",
    "    ax.set_ylabel('Likelihood of spiking (%)')\n",
    "    ax.set_xlabel(\"Phase\")\n",
    "    ax.set_xticks([0.375, 1.125])\n",
    "    ax.set_ylim([0, 100])\n",
    "    \n",
    "    # Set custom labels for x-axis\n",
    "    labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "    labels[:] = ['Swing', 'Stance']\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    # Configure minor ticks\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "    \n",
    "    # Adjust layout and save the figure\n",
    "    fig.tight_layout(pad=parameters['pad'])\n",
    "    fig.savefig(f'images/motion_primitive_neuron/{naming[i]}.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54a9e9dba4c5a221"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cell plots a distribution of scores for the two target vectors, grouped per leg."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a6061383476a01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split up the scores pef leg for the two target vectors\n",
    "scores_per_leg = [\n",
    "    np.concatenate((scores[i][(j + 0) * N_PN_PER_LEG:(j + 1) * N_PN_PER_LEG], \n",
    "                    scores[i][(j + 3) * N_PN_PER_LEG:(j + 4) * N_PN_PER_LEG])) \n",
    "    for i in range(2) for j in range(3)\n",
    "]\n",
    "\n",
    "# Define naming\n",
    "score_leg_names = [\n",
    "    f'Leg: {j}\\n{i}' \n",
    "    for i in ['Stance / Swing', 'St→Sw / Sw→St'] \n",
    "    for j in ['Front', 'Middle', 'Hind']\n",
    "]\n",
    "\n",
    "# Create a figure with 2 rows and 3 columns of subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(5.2, 4))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define histogram range and bins\n",
    "bin_range = (0, 1)\n",
    "bins = np.arange(0, 1.1, 0.025)  # Steps of 0.1\n",
    "\n",
    "# Plot each array in a separate subplot\n",
    "for i, arr in enumerate(scores_per_leg):\n",
    "    # Plot histogram\n",
    "    counts, edges, patches = axes[i].hist(arr, bins=bins, range=bin_range, edgecolor='black', color=custom_colors[0], zorder=100)\n",
    "    \n",
    "    # Set title and axis limits\n",
    "    axes[i].set_title(score_leg_names[i])\n",
    "    axes[i].set_xlim(0, 1)\n",
    "    axes[i].set_ylim(0, 35)  # Adjust based on expected counts\n",
    "    axes[i].set_yticks([0, 5, 10, 15, 20, 25])\n",
    "    axes[i].set_xticks([0, .25, .5, .75, 1])\n",
    "    \n",
    "    # Calculate and annotate MP IN below 25th and above 75th percentile\n",
    "    count_25 = 0\n",
    "    count_75 = 0\n",
    "    for j, patch in enumerate(patches):\n",
    "        if edges[j] < 0.250:\n",
    "            patch.set_facecolor(color=custom_colors[1])\n",
    "            count_25 += counts[j]\n",
    "        elif edges[j] > 0.749:\n",
    "            patch.set_facecolor(color=custom_colors[2])\n",
    "            count_75 += counts[j]\n",
    "        else:\n",
    "            patch.set_facecolor(color=custom_colors[0])\n",
    "    \n",
    "    # Annotate MP INs and draw arrows\n",
    "    axes[i].text(0.1, 10, f'{int(count_25)}', color=custom_colors[1], ha='center')\n",
    "    axes[i].text(0.9, 10, f'{int(count_75)}', color=custom_colors[2], ha='center')\n",
    "    axes[i].arrow(0.1, 9, 0.05, -10, color=custom_colors[1])\n",
    "    axes[i].arrow(0.9, 9, -0.05, -10, color=custom_colors[2])\n",
    "    \n",
    "    # Plot vertical dashed lines at 5th and 95th percentiles (data driven high performers)\n",
    "    percentile_95 = np.percentile(arr, 95)\n",
    "    percentile_5 = np.percentile(arr, 5)\n",
    "    axes[i].plot([percentile_5, percentile_5], [0, 35], color='black', linestyle='dotted')\n",
    "    axes[i].plot([percentile_95, percentile_95], [0, 35], color='black', linestyle='dotted')\n",
    "    \n",
    "    # Annotate percentiles with values\n",
    "    axes[i].text(percentile_5, 30, f'{percentile_5:.2f}', ha='center', \n",
    "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='square,pad=0.1', linestyle='solid'))\n",
    "    axes[i].text(percentile_95, 30, f'{percentile_95:.2f}', ha='center',\n",
    "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='square,pad=0.1', linestyle='solid'))\n",
    "\n",
    "# Set labels for x-axis of last row of subplots and y-axis of first column\n",
    "for i in [3, 4, 5]:\n",
    "    axes[i].set_xlabel('Score')\n",
    "\n",
    "for i in [0, 3]:\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure with tight bounding box\n",
    "fig.savefig(f'images/motion_primitive_neuron/P2_fig6.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d25e7214a184d773"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following plot was created to identify which first-order interneurons (INs) contributed most significantly to swing and stance encoding. To achieve this, the swing scores for all motion primitive (MP) interneurons (INs) were grouped according to velocity and position IN inputs for the three joints and six legs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7eaa00c26548b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "N_LEGS = 6\n",
    "N_JOINTS = 3\n",
    "N_NEURON_TYPES = 5\n",
    "N_PRIMITIVE_NEURONS_LEG = N_PRIMITIVE_NEURONS // N_LEGS\n",
    "\n",
    "# Initialize the array with zeros\n",
    "swing_scores_array = np.full((N_LEGS, N_JOINTS, N_NEURON_TYPES, 24), 0.0)\n",
    "\n",
    "# Reshape the swing scores, (N_LEGS, N_PRIMITIVE_NEURONS_LEG)\n",
    "swing_scores = scores[0].reshape(N_LEGS, -1)\n",
    "\n",
    "# Populate the swing_scores_array\n",
    "for i in range(N_LEGS):\n",
    "    for j in range(N_PRIMITIVE_NEURONS_LEG):\n",
    "        for k in range(N_JOINTS):\n",
    "            first_zero_index = np.where(swing_scores_array[i, k, perm2[j][k], :] == 0)[0][0]\n",
    "            swing_scores_array[i, k, perm2[j][k], first_zero_index] = swing_scores[i, j]\n",
    "\n",
    "# Remove the third axis\n",
    "swing_scores_array = np.delete(swing_scores_array, 0, axis=2)\n",
    "\n",
    "# Calculate statistics: average, max, 25% and 75%\n",
    "swings_average = np.median(swing_scores_array, axis=3)\n",
    "swings_max = np.percentile(swing_scores_array, 90, axis=3) - swings_average\n",
    "swings_min = swings_average - np.percentile(swing_scores_array, 10, axis=3)\n",
    "swings_25 = np.percentile(swing_scores_array, 25, axis=3)\n",
    "swings_75 = np.percentile(swing_scores_array, 75, axis=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ac67ea0db0d2360"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "x = [0, 1, 2, 3, 6, 7, 8, 9, 12, 13, 14, 15]\n",
    "LEGS = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "Y_AXIS_LIMITS = [0.15, 0.85]\n",
    "X_AXIS_LIMITS = [-0.3, 2.9]\n",
    "Y_TICKS = [0.25, 0.5, 0.75]\n",
    "X_TICKS = [0.3, 1.3, 2.3]\n",
    "X_LABELS = ['α', 'β', 'γ']\n",
    "LEGEND_LABELS = ['vel-', 'vel+', 'pos-', 'pos+']\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(5.2, 4))\n",
    "\n",
    "# Loop through each subplot\n",
    "for k in range(6):\n",
    "    ax = axes[k // 3, k % 3]  # Select the subplot\n",
    "    ax.set_ylim(Y_AXIS_LIMITS)  # Set y-axis limits\n",
    "    ax.set_xlim(X_AXIS_LIMITS)  # Set x-axis limits\n",
    "\n",
    "    # Add dotted lines at y = 0.25, 0.5, 0.75\n",
    "    for y_val in Y_TICKS:\n",
    "        ax.plot([-2, 5], [y_val, y_val], linestyle='dotted', color='black', zorder=0)\n",
    "\n",
    "    # Loop through each condition (vel-, vel+, pos-, pos+)\n",
    "    for j in range(4):\n",
    "        # Plot error bars for the swing scores\n",
    "        ax.errorbar(np.array([0, 1, 2]) + 0.2 * j, swings_average[k, :, j],\n",
    "                    yerr=[swings_min[k, :, j], swings_max[k, :, j]], capsize=3, fmt='None', color=custom_colors[j + 1])\n",
    "\n",
    "        # Add rectangles for the 25th to 75th percentile range\n",
    "        for i in range(3):\n",
    "            ax.add_patch(Rectangle((i + 0.2 * j - 0.08, swings_25[k, i, j]), 0.16,\n",
    "                                   swings_75[k, i, j] - swings_25[k, i, j], facecolor=custom_colors[j + 1]))\n",
    "            # Add a black line for the median value\n",
    "            ax.add_patch(Rectangle((i + 0.2 * j - 0.08, swings_average[k, i, j] - 0.0025), 0.16, 0.005, facecolor='black',\n",
    "                                   zorder=10))\n",
    "\n",
    "    # Set y-ticks for the first column of subplots\n",
    "    if k % 3 != 0:\n",
    "        ax.set_yticks([])\n",
    "    else:\n",
    "        ax.set_yticks(Y_TICKS)\n",
    "\n",
    "    # Set x-ticks and labels for the second row of subplots\n",
    "    if k // 3 == 1:\n",
    "        ax.set_xticks(X_TICKS)\n",
    "        ax.set_xticklabels(X_LABELS)\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    ax.set_title(LEGS[k])\n",
    "\n",
    "# Add a y-axis label for the entire figure\n",
    "fig.supylabel('Swing score')\n",
    "\n",
    "# Create custom legend elements\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', label=LEGEND_LABELS[i], markerfacecolor=custom_colors[i + 1], markersize=7)\n",
    "    for i in range(len(LEGEND_LABELS))\n",
    "]\n",
    "# Add legend to the figure\n",
    "fig.legend(handles=legend_elements, loc='lower center', bbox_to_anchor=(0.5, -0.03), ncol=4, frameon=False)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('images/motion_primitive_neuron/P2_fig5.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea0cc5caad0fe5f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cell tabulates the scores of a paired t-test between $vel_-$-$vel_+$ and $pos_-$-$pos_+$, respectively for each combination in the previous cell. High t-scores are expected for second-layer INs that fire more frequently during a specific phase compared to their negative counterpart."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1901a2d3fb8fa8a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the angles and leg labels\n",
    "angles = [r'$\\alpha$', r'$\\beta$', r'$\\gamma$']\n",
    "legs = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "\n",
    "# Initialize arrays to store t-test results for position and velocity\n",
    "t_test_pos = np.zeros_like(swing_scores_array[:, :, 0, 0])\n",
    "t_test_vel = np.zeros_like(swing_scores_array[:, :, 0, 0])\n",
    "\n",
    "# Perform paired t-tests for each leg and joint\n",
    "for i in range(N_LEGS):\n",
    "    for j in range(N_JOINTS):\n",
    "        # t-test between vel+ and vel- scores\n",
    "        t_test_vel[i, j] = stats.ttest_rel(swing_scores_array[i, j, 1, :], swing_scores_array[i, j, 0, :])[0]\n",
    "        # t-test between pos+ and pos- scores\n",
    "        t_test_pos[i, j] = stats.ttest_rel(swing_scores_array[i, j, 3, :], swing_scores_array[i, j, 2, :])[0]\n",
    "\n",
    "# Create DataFrames to hold the t-test results and round them to 2 decimal places\n",
    "df_vel = pd.DataFrame(data=np.around(t_test_vel.T, 2), index=angles, columns=legs)\n",
    "df_pos = pd.DataFrame(data=np.around(t_test_pos.T, 2), index=angles, columns=legs)\n",
    "\n",
    "# Save the t-test results to CSV files\n",
    "df_vel.to_csv('results/primitive_t_test_vel.csv')\n",
    "df_pos.to_csv('results/primitive_t_test_pos.csv')\n",
    "\n",
    "# Print the DataFrames to display the results\n",
    "print(df_vel)\n",
    "print(df_pos)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7c40236df382255"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
